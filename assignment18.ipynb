{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "1e83e2ec-e2f1-4ecf-bbd8-c69235f7c9bd",
   "metadata": {},
   "source": [
    "# Ans1-"
   ]
  },
  {
   "cell_type": "raw",
   "id": "9b48d584-21ee-4a45-80c1-aa7ea852bffa",
   "metadata": {},
   "source": [
    "The filter method in feature selection involves evaluating each feature independently and ranking them based on certain criteria, such as statistical measures or correlation. \n",
    "\n",
    "How it works:\n",
    "\n",
    "Compute a metric: Calculate a statistical metric for each feature, like correlation, information gain, chi-squared, or mutual information.\n",
    "\n",
    "Rank features: Rank the features based on their individual scores.\n",
    "\n",
    "Select top features: Choose the top-ranked features according to a specified threshold."
   ]
  },
  {
   "cell_type": "raw",
   "id": "33052095-f700-40e6-af30-081a4db3e770",
   "metadata": {},
   "source": [
    "Example:\n",
    "Let's say you have a dataset with features A, B, and C, and you want to select the most relevant features.\n",
    "\n",
    "Step 1: Calculate correlation coefficients for each feature with the target variable.\n",
    "\n",
    "Step 2: Rank the features based on their correlation values.\n",
    "\n",
    "Step 3: Set a threshold (e.g., top 2 features), and select those features."
   ]
  },
  {
   "cell_type": "raw",
   "id": "71390924-7ac0-49a0-a95f-2a0db04312d2",
   "metadata": {},
   "source": [
    "Correlation with Target:\n",
    "A: 0.7\n",
    "B: 0.5\n",
    "C: 0.2\n",
    "\n",
    "Ranking:\n",
    "1. A\n",
    "2. B\n",
    "3. C\n",
    "\n",
    "Selected Features (Threshold = Top 2):\n",
    "[A, B]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b86a942-747a-442b-84b2-62cd7047027c",
   "metadata": {},
   "source": [
    "# Ans2-"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0024523c-9163-4a44-b471-cf3ddbae29eb",
   "metadata": {},
   "source": [
    "Filter Method:\n",
    "\n",
    "Selection Criterion: Features are selected based on certain statistical measures or criteria, independent of the machine learning model.\n",
    "\n",
    "Independence: Each feature is evaluated separately without considering the impact of other features.\n",
    "\n",
    "Computational Efficiency: Generally faster because it doesn't involve training a machine learning model."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b7b5e3e5-f095-4763-8934-4d3047c56c29",
   "metadata": {},
   "source": [
    "Filter method selects features based on intrinsic characteristics.\n",
    "\n",
    "Wrapper method selects features based on their impact on the performance of a specific machine learning model.\n",
    "\n",
    "In essence, the filter method is generally faster but may not capture the interactions between features. The wrapper method, on the other hand, considers these interactions but is more computationally intensive. The choice between them depends on the specific problem, dataset, and computational resources available.\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b1f77049-7c75-47fc-8d89-5ab984542ef7",
   "metadata": {},
   "source": [
    "# Ans3-"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e96a71a3-7cb5-40f9-a31c-f161e2d3d9b9",
   "metadata": {},
   "source": [
    "some comman technique to use embedded feature selection"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f84a67af-f1a6-4d44-ad46-afd7af5d9715",
   "metadata": {},
   "source": [
    "lasso (least absolute shrinkage selection operator)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f8753479-7727-41d3-990f-714793157c67",
   "metadata": {},
   "source": [
    "decision tree with feature importance -Decision trees can be used for feature selection by assessing the importance of each feature."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "10c8485c-60a7-4448-b3d9-68b628a38eaa",
   "metadata": {},
   "source": [
    "Random forest-An ensemble of decision trees where each tree is built on a random subset of features."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5208c2c5-eb7b-4f06-9f34-3f0a161c97e7",
   "metadata": {},
   "source": [
    "Gradient Boosting: Builds trees sequentially, each correcting the errors of the previous one"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "107544ef-2168-42a2-89c9-60baa9008cb3",
   "metadata": {},
   "source": [
    "elastic net- Combines L1 (LASSO) and L2 (Ridge) regularization, providing a balance between feature selection and maintaining correlated features."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0cf6c604-8996-4f5a-9b4e-c21d577ff670",
   "metadata": {},
   "source": [
    "XGBoost-n efficient gradient boosting framework with a built-in feature selection mechanism."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f8056521-c0fa-449a-8424-3575692a463e",
   "metadata": {},
   "source": [
    "# Ans4-"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f6b29db2-4c53-4b10-a19f-347dfc7bebd5",
   "metadata": {},
   "source": [
    " Ignores Feature Interactions-The filter method evaluates features independently ignoring dependency between features."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c211851c-af84-4996-b85b-e9e52b085d8b",
   "metadata": {},
   "source": [
    "Not model specific-means filter method does not take ml alorithm that will be used on the datasests."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f4b0a34-15d0-4d51-9852-b64e4a2ec625",
   "metadata": {},
   "source": [
    "Limited in Handling Non-Linear Relationships:because filter method is based io the linear relationships."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b03b249a-ddf3-4e81-b0a2-e2b691897a90",
   "metadata": {},
   "source": [
    "# Ans5-"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4db23747-ffd3-4020-aea8-075132ed5919",
   "metadata": {},
   "source": [
    "In which situations would you prefer using the Filter method over the Wrapper method for feature \n",
    "selection?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9279fb3f-8dea-462e-8818-0b9373148174",
   "metadata": {},
   "source": [
    "Use the Filter method for feature selection when computational efficiency is crucial, and you want a quick pre-processing step that considers each feature independently without involving the complexity of model training."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7de6f01f-65de-43f4-bcf1-3664473f5548",
   "metadata": {},
   "source": [
    "# Ans6-"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d4e7ac5c-b1fc-44cb-9046-8a29a231da53",
   "metadata": {},
   "source": [
    "In the telecom company's customer churn project, I would use the Filter Method to select pertinent attributes by calculating relevant metrics for each feature, such as correlation with customer churn, information gain, or mutual information. I would then rank the features based on these metrics and choose the top ones that exhibit a strong statistical relationship with customer churn, providing a quick and computationally efficient initial feature selection for the predictive model."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6139b822-1941-4992-81b8-375ae378fc76",
   "metadata": {},
   "source": [
    "# Ans7-"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa596000-af45-4edd-be9e-9d02c50c5eea",
   "metadata": {},
   "source": [
    "In the soccer match outcome prediction project, I would employ the Embedded method by using machine learning algorithms that inherently perform feature selection during their training process. Techniques such as Regularized Regression models (e.g., LASSO or Ridge), Decision Trees with feature importance, Random Forests, or Gradient Boosting can be applied. These algorithms assign importance scores to each feature based on their contribution to the model's predictive performance. I would then select the features with the highest importance scores, ensuring that the model considers the most relevant aspects of player statistics and team rankings for accurate predictions."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ee10384-e9ee-41c0-b326-9b1a9ffa35f9",
   "metadata": {},
   "source": [
    "# Ans8-"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d485a38-e106-4383-a111-31cdb1f5acee",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
